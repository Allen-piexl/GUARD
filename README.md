# GUARD
GUARD: Role-playing to Generate Natural-language Jailbreakings to Test Guideline Adherence of LLMs
